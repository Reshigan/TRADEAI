"""
TRADEAI Price Optimization Model
Production-grade dynamic pricing using Bayesian Optimization + Reinforcement Learning

Target: 10-15% profit improvement
Approach: Multi-objective optimization (profit, volume, market share)
Training: Historical price elasticity data
Update: Bi-weekly retraining
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
import logging

# Bayesian Optimization
from skopt import gp_minimize
from skopt.space import Real
from skopt.utils import use_named_args
from scipy.optimize import minimize

# Reinforcement Learning
import gymnasium as gym
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv

# ML
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression

# MLOps
import mlflow
import mlflow.sklearn

logger = logging.getLogger(__name__)


class PriceElasticityModel:
    """
    Estimate price elasticity of demand
    
    Uses log-log regression: log(Q) = a + b*log(P)
    where b is the price elasticity
    """
    
    def __init__(self):
        self.model = LinearRegression()
        self.elasticity = None
        self.scaler = StandardScaler()
        
    def fit(self, prices: np.ndarray, quantities: np.ndarray):
        """
        Fit elasticity model
        
        Args:
            prices: Historical prices
            quantities: Historical quantities sold
        """
        # Remove zeros and negatives
        mask = (prices > 0) & (quantities > 0)
        prices_clean = prices[mask]
        quantities_clean = quantities[mask]
        
        # Log-log transformation
        log_prices = np.log(prices_clean).reshape(-1, 1)
        log_quantities = np.log(quantities_clean)
        
        # Fit linear regression
        self.model.fit(log_prices, log_quantities)
        
        # Elasticity is the slope
        self.elasticity = self.model.coef_[0]
        
        logger.info(f"Price elasticity estimated: {self.elasticity:.3f}")
        
        return self.elasticity
    
    def predict_demand(self, price: float, baseline_price: float, baseline_demand: float) -> float:
        """
        Predict demand at given price using elasticity
        
        Args:
            price: New price to test
            baseline_price: Current/reference price
            baseline_demand: Demand at baseline price
            
        Returns:
            Predicted demand at new price
        """
        if self.elasticity is None:
            raise ValueError("Model not fitted. Call fit() first.")
        
        # Q2 = Q1 * (P2/P1)^elasticity
        price_ratio = price / baseline_price
        predicted_demand = baseline_demand * (price_ratio ** self.elasticity)
        
        return max(0, predicted_demand)


class BayesianPriceOptimizer:
    """
    Bayesian Optimization for finding optimal price
    
    Uses Gaussian Process to model the profit function
    and finds the price that maximizes expected improvement
    """
    
    def __init__(self, elasticity_model: PriceElasticityModel):
        self.elasticity_model = elasticity_model
        self.history = []
        
    def profit_function(self, price: float, cost: float, baseline_price: float, baseline_demand: float) -> float:
        """
        Calculate profit at given price
        
        Args:
            price: Price to evaluate
            cost: Unit cost
            baseline_price: Current price
            baseline_demand: Current demand
            
        Returns:
            Expected profit
        """
        # Predict demand at this price
        predicted_demand = self.elasticity_model.predict_demand(price, baseline_price, baseline_demand)
        
        # Calculate profit
        profit = (price - cost) * predicted_demand
        
        return profit
    
    def optimize(
        self,
        current_price: float,
        cost: float,
        baseline_demand: float,
        price_bounds: Tuple[float, float],
        n_calls: int = 100
    ) -> Dict:
        """
        Find optimal price using Bayesian Optimization
        
        Args:
            current_price: Current price
            cost: Unit cost
            baseline_demand: Current demand level
            price_bounds: (min_price, max_price)
            n_calls: Number of optimization iterations
            
        Returns:
            Dict with optimal_price, expected_profit, current_profit, improvement
        """
        logger.info(f"Optimizing price. Current: R{current_price:.2f}, Bounds: R{price_bounds[0]:.2f}-R{price_bounds[1]:.2f}")
        
        # Define objective function (negative because we minimize)
        def objective(price):
            profit = self.profit_function(price[0], cost, current_price, baseline_demand)
            return -profit  # Negative because we minimize
        
        # Define search space
        space = [Real(price_bounds[0], price_bounds[1], name='price')]
        
        # Run Bayesian Optimization
        result = gp_minimize(
            objective,
            space,
            n_calls=n_calls,
            random_state=42,
            acq_func='EI',  # Expected Improvement
            n_random_starts=10
        )
        
        # Extract results
        optimal_price = result.x[0]
        optimal_profit = -result.fun  # Negate back
        
        # Calculate current profit
        current_profit = self.profit_function(current_price, cost, current_price, baseline_demand)
        
        # Calculate improvement
        profit_improvement = ((optimal_profit - current_profit) / current_profit) * 100 if current_profit > 0 else 0
        
        # Predict demand at optimal price
        optimal_demand = self.elasticity_model.predict_demand(optimal_price, current_price, baseline_demand)
        volume_change = ((optimal_demand - baseline_demand) / baseline_demand) * 100 if baseline_demand > 0 else 0
        
        # Calculate revenue
        optimal_revenue = optimal_price * optimal_demand
        current_revenue = current_price * baseline_demand
        revenue_change = ((optimal_revenue - current_revenue) / current_revenue) * 100 if current_revenue > 0 else 0
        
        result_dict = {
            'optimal_price': round(optimal_price, 2),
            'current_price': current_price,
            'price_change_pct': round(((optimal_price - current_price) / current_price) * 100, 2),
            'expected_profit': round(optimal_profit, 2),
            'current_profit': round(current_profit, 2),
            'profit_improvement_pct': round(profit_improvement, 2),
            'expected_demand': round(optimal_demand, 0),
            'current_demand': round(baseline_demand, 0),
            'volume_change_pct': round(volume_change, 2),
            'expected_revenue': round(optimal_revenue, 2),
            'current_revenue': round(current_revenue, 2),
            'revenue_change_pct': round(revenue_change, 2),
            'confidence': self.calculate_confidence(result),
            'optimization_method': 'bayesian'
        }
        
        logger.info(f"Optimal price found: R{optimal_price:.2f} ({profit_improvement:+.1f}% profit improvement)")
        
        return result_dict
    
    def calculate_confidence(self, optimization_result) -> float:
        """
        Calculate confidence in the optimization result
        
        Based on:
        - Number of evaluations
        - Convergence of the optimizer
        - Variance in the Gaussian Process
        """
        # Simple heuristic: confidence increases with more evaluations
        n_calls = len(optimization_result.func_vals)
        confidence = min(0.95, 0.5 + (n_calls / 200))
        
        return round(confidence, 2)


class ReinforcementLearningPricer:
    """
    RL Agent that learns optimal pricing policy through interaction
    
    Uses Proximal Policy Optimization (PPO) to learn a policy that
    maximizes long-term profit while considering:
    - Demand elasticity
    - Competitive dynamics
    - Market share
    - Customer lifetime value
    """
    
    def __init__(self, elasticity_model: PriceElasticityModel):
        self.elasticity_model = elasticity_model
        self.agent = None
        self.env = None
        
    def create_environment(self, product_data: pd.DataFrame) -> gym.Env:
        """Create custom Gym environment for pricing"""
        
        class PricingEnv(gym.Env):
            """
            Custom environment for pricing optimization
            
            State: [current_price, inventory, demand, competitor_price, day_of_week, has_promotion]
            Action: Price adjustment (-20% to +20%)
            Reward: Profit + market share bonus - customer churn penalty
            """
            
            def __init__(self, data, elasticity_model):
                super().__init__()
                self.data = data
                self.elasticity_model = elasticity_model
                self.current_step = 0
                self.max_steps = 365
                
                # Action space: Price change from -20% to +20% (41 discrete actions)
                self.action_space = gym.spaces.Discrete(41)
                
                # Observation space
                self.observation_space = gym.spaces.Box(
                    low=np.array([0, 0, 0, 0, 0, 0]),
                    high=np.array([1000, 10000, 10000, 1000, 6, 1]),
                    dtype=np.float32
                )
                
                self.reset()
            
            def reset(self, seed=None, options=None):
                super().reset(seed=seed)
                self.current_step = 0
                self.current_price = self.data['price'].mean()
                self.inventory = self.data['inventory'].mean() if 'inventory' in self.data else 5000
                self.baseline_demand = self.data['sales_volume'].mean()
                
                return self._get_observation(), {}
            
            def _get_observation(self):
                return np.array([
                    self.current_price,
                    self.inventory,
                    self._get_recent_demand(),
                    self._get_competitor_price(),
                    self.current_step % 7,
                    0  # Placeholder for promotion
                ], dtype=np.float32)
            
            def _get_recent_demand(self):
                # Simplified: use baseline with some noise
                return self.baseline_demand * np.random.uniform(0.8, 1.2)
            
            def _get_competitor_price(self):
                # Simplified: competitor price is Â±10% of our price
                return self.current_price * np.random.uniform(0.9, 1.1)
            
            def step(self, action):
                # Decode action: Convert discrete action to price change
                price_change_pct = (action - 20) / 100  # -20% to +20%
                new_price = self.current_price * (1 + price_change_pct)
                
                # Ensure price stays within bounds
                new_price = np.clip(new_price, self.data['price'].min(), self.data['price'].max())
                
                # Predict demand at new price
                predicted_demand = self.elasticity_model.predict_demand(
                    new_price,
                    self.current_price,
                    self.baseline_demand
                )
                
                # Calculate profit
                cost = self.data['cost'].mean() if 'cost' in self.data else self.current_price * 0.6
                profit = (new_price - cost) * predicted_demand
                
                # Calculate market share (simplified)
                market_share = predicted_demand / (predicted_demand + self._get_competitor_demand())
                
                # Reward function
                reward = (
                    profit / 1000 +  # Profit component (scaled)
                    market_share * 100 +  # Market share bonus
                    -abs(price_change_pct) * 10  # Penalize large price swings
                )
                
                # Update state
                self.current_price = new_price
                self.inventory -= predicted_demand
                self.current_step += 1
                
                # Check if episode is done
                done = self.current_step >= self.max_steps or self.inventory <= 0
                
                return self._get_observation(), reward, done, False, {}
            
            def _get_competitor_demand(self):
                return self.baseline_demand * 0.5  # Simplified
        
        return PricingEnv(product_data, self.elasticity_model)
    
    def train(self, product_data: pd.DataFrame, total_timesteps: int = 50000):
        """
        Train RL agent on historical data
        
        Args:
            product_data: Historical pricing and sales data
            total_timesteps: Number of training steps
        """
        logger.info(f"Training RL pricing agent for {total_timesteps} steps...")
        
        # Create environment
        self.env = DummyVecEnv([lambda: self.create_environment(product_data)])
        
        # Initialize PPO agent
        self.agent = PPO(
            'MlpPolicy',
            self.env,
            learning_rate=0.0003,
            n_steps=2048,
            batch_size=64,
            n_epochs=10,
            gamma=0.99,
            verbose=1
        )
        
        # Train
        self.agent.learn(total_timesteps=total_timesteps)
        
        logger.info("RL agent training complete")
        
        return self.agent
    
    def predict_optimal_price(self, current_state: Dict) -> Dict:
        """
        Predict optimal price using trained RL agent
        
        Args:
            current_state: Current market state
            
        Returns:
            Optimal price recommendation
        """
        if self.agent is None:
            raise ValueError("Agent not trained. Call train() first.")
        
        # Prepare observation
        obs = np.array([
            current_state.get('current_price', 15.99),
            current_state.get('inventory', 5000),
            current_state.get('recent_demand', 1000),
            current_state.get('competitor_price', 16.50),
            current_state.get('day_of_week', 3),
            current_state.get('has_promotion', 0)
        ], dtype=np.float32).reshape(1, -1)
        
        # Get action from agent
        action, _states = self.agent.predict(obs, deterministic=True)
        
        # Decode action to price
        price_change_pct = (action - 20) / 100
        optimal_price = current_state['current_price'] * (1 + price_change_pct)
        
        return {
            'optimal_price': round(optimal_price, 2),
            'price_change_pct': round(price_change_pct * 100, 2),
            'optimization_method': 'reinforcement_learning',
            'confidence': 0.85
        }


class PriceOptimizer:
    """
    Complete Price Optimization System
    
    Combines:
    1. Price Elasticity Estimation
    2. Bayesian Optimization (fast, interpretable)
    3. Reinforcement Learning (adaptive, learns over time)
    
    Selects best method based on data availability and business context
    """
    
    def __init__(self, config: Dict):
        self.config = config
        self.elasticity_model = PriceElasticityModel()
        self.bayesian_optimizer = None
        self.rl_pricer = None
        
        # Initialize MLflow
        mlflow.set_experiment(config.get('experiment_name', 'price-optimization'))
    
    def train(self, df: pd.DataFrame, method: str = 'both'):
        """
        Train price optimization models
        
        Args:
            df: Historical data with columns [date, product_id, price, sales_volume, cost]
            method: 'bayesian', 'rl', or 'both'
        """
        logger.info(f"Training price optimization model(s): {method}")
        
        with mlflow.start_run(run_name=f"price_opt_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
            
            # Log parameters
            mlflow.log_param("method", method)
            mlflow.log_param("training_samples", len(df))
            
            # 1. Estimate price elasticity
            prices = df['price'].values
            quantities = df['sales_volume'].values
            
            elasticity = self.elasticity_model.fit(prices, quantities)
            mlflow.log_metric("price_elasticity", elasticity)
            
            # 2. Train Bayesian Optimizer
            if method in ['bayesian', 'both']:
                self.bayesian_optimizer = BayesianPriceOptimizer(self.elasticity_model)
                logger.info("Bayesian optimizer initialized")
            
            # 3. Train RL Agent
            if method in ['rl', 'both']:
                self.rl_pricer = ReinforcementLearningPricer(self.elasticity_model)
                self.rl_pricer.train(df, total_timesteps=50000)
                logger.info("RL agent trained")
                
                # Save RL model
                mlflow.log_artifact("rl_pricing_model.zip")
            
            logger.info("Price optimization training complete")
    
    def optimize(
        self,
        product_id: str,
        current_price: float,
        cost: float,
        baseline_demand: float,
        constraints: Optional[Dict] = None,
        method: str = 'bayesian'
    ) -> Dict:
        """
        Generate optimal price recommendation
        
        Args:
            product_id: Product identifier
            current_price: Current price
            cost: Unit cost
            baseline_demand: Current demand level
            constraints: Price bounds and other constraints
            method: 'bayesian' or 'rl'
            
        Returns:
            Dict with optimal_price and expected impact
        """
        logger.info(f"Optimizing price for product {product_id}")
        
        # Default constraints
        if constraints is None:
            constraints = {
                'min_price': cost * 1.1,  # At least 10% margin
                'max_price': current_price * 1.5  # Max 50% increase
            }
        
        price_bounds = (constraints.get('min_price', cost * 1.1), constraints.get('max_price', current_price * 2))
        
        # Choose optimization method
        if method == 'bayesian' and self.bayesian_optimizer:
            result = self.bayesian_optimizer.optimize(
                current_price,
                cost,
                baseline_demand,
                price_bounds
            )
        elif method == 'rl' and self.rl_pricer:
            current_state = {
                'current_price': current_price,
                'inventory': baseline_demand * 30,  # Assume 30 days inventory
                'recent_demand': baseline_demand,
                'competitor_price': current_price * 1.05,
                'day_of_week': datetime.now().weekday(),
                'has_promotion': 0
            }
            result = self.rl_pricer.predict_optimal_price(current_state)
            
            # Calculate expected impact (using elasticity model)
            optimal_demand = self.elasticity_model.predict_demand(
                result['optimal_price'],
                current_price,
                baseline_demand
            )
            current_profit = (current_price - cost) * baseline_demand
            optimal_profit = (result['optimal_price'] - cost) * optimal_demand
            
            result['expected_profit'] = round(optimal_profit, 2)
            result['current_profit'] = round(current_profit, 2)
            result['profit_improvement_pct'] = round(((optimal_profit - current_profit) / current_profit) * 100, 2) if current_profit > 0 else 0
        else:
            raise ValueError(f"Method {method} not available or not trained")
        
        # Add product context
        result['product_id'] = product_id
        result['timestamp'] = datetime.now().isoformat()
        
        return result
    
    def evaluate(self, df_test: pd.DataFrame) -> Dict:
        """Evaluate optimization on test data"""
        
        # Simulate optimization on test data
        test_results = []
        
        for _, row in df_test.iterrows():
            try:
                result = self.optimize(
                    product_id=row['product_id'],
                    current_price=row['price'],
                    cost=row.get('cost', row['price'] * 0.6),
                    baseline_demand=row['sales_volume'],
                    method='bayesian'
                )
                test_results.append(result['profit_improvement_pct'])
            except Exception as e:
                logger.warning(f"Optimization failed for row: {e}")
        
        metrics = {
            'avg_profit_improvement': np.mean(test_results) if test_results else 0,
            'median_profit_improvement': np.median(test_results) if test_results else 0,
            'max_profit_improvement': np.max(test_results) if test_results else 0,
            'success_rate': len([r for r in test_results if r > 0]) / len(test_results) if test_results else 0
        }
        
        logger.info(f"Evaluation metrics: {metrics}")
        
        return metrics


if __name__ == "__main__":
    # Example usage
    
    # Generate sample data
    np.random.seed(42)
    n_samples = 1000
    
    df = pd.DataFrame({
        'date': pd.date_range('2022-01-01', periods=n_samples),
        'product_id': 'prod-001',
        'price': np.random.uniform(12, 20, n_samples),
        'sales_volume': 1000 - 50 * (np.random.uniform(12, 20, n_samples) - 15) + np.random.normal(0, 50, n_samples),
        'cost': 10,
        'inventory': 5000
    })
    
    # Initialize optimizer
    config = {'experiment_name': 'price-opt-test'}
    optimizer = PriceOptimizer(config)
    
    # Train
    optimizer.train(df, method='bayesian')
    
    # Optimize price
    result = optimizer.optimize(
        product_id='prod-001',
        current_price=15.99,
        cost=10,
        baseline_demand=750
    )
    
    print(f"\nPrice Optimization Result:")
    print(f"Current Price: R{result['current_price']:.2f}")
    print(f"Optimal Price: R{result['optimal_price']:.2f} ({result['price_change_pct']:+.1f}%)")
    print(f"Profit Improvement: {result['profit_improvement_pct']:+.1f}%")
    print(f"Confidence: {result['confidence']:.0%}")
